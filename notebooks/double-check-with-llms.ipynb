{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":80878,"databundleVersionId":8891242,"sourceType":"competition"}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setting up","metadata":{}},{"cell_type":"code","source":"import os\n\nos.environ[\"OPENAI_API_KEY\"] = \"sk-your-api-key\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-30T12:33:41.048711Z","iopub.execute_input":"2024-07-30T12:33:41.049299Z","iopub.status.idle":"2024-07-30T12:33:41.058499Z","shell.execute_reply.started":"2024-07-30T12:33:41.049149Z","shell.execute_reply":"2024-07-30T12:33:41.055269Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\ntest_df = pd.read_csv('/kaggle/input/llm-zoomcamp-2024-competition/test.csv')","metadata":{"execution":{"iopub.status.busy":"2024-07-30T12:33:48.717455Z","iopub.execute_input":"2024-07-30T12:33:48.717888Z","iopub.status.idle":"2024-07-30T12:33:49.181459Z","shell.execute_reply.started":"2024-07-30T12:33:48.717851Z","shell.execute_reply":"2024-07-30T12:33:49.180405Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"! pip install langchain-openai","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"jupyter":{"source_hidden":true,"outputs_hidden":true},"execution":{"iopub.status.busy":"2024-07-30T12:35:31.173633Z","iopub.execute_input":"2024-07-30T12:35:31.174493Z","iopub.status.idle":"2024-07-30T12:35:50.702767Z","shell.execute_reply.started":"2024-07-30T12:35:31.174456Z","shell.execute_reply":"2024-07-30T12:35:50.701469Z"},"collapsed":true,"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Collecting langchain-openai\n  Downloading langchain_openai-0.1.19-py3-none-any.whl.metadata (2.6 kB)\nCollecting langchain-core<0.3.0,>=0.2.24 (from langchain-openai)\n  Downloading langchain_core-0.2.24-py3-none-any.whl.metadata (6.2 kB)\nCollecting openai<2.0.0,>=1.32.0 (from langchain-openai)\n  Downloading openai-1.37.1-py3-none-any.whl.metadata (22 kB)\nCollecting tiktoken<1,>=0.7 (from langchain-openai)\n  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.24->langchain-openai) (6.0.1)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.24->langchain-openai) (1.33)\nCollecting langsmith<0.2.0,>=0.1.75 (from langchain-core<0.3.0,>=0.2.24->langchain-openai)\n  Downloading langsmith-0.1.94-py3-none-any.whl.metadata (13 kB)\nCollecting packaging<25,>=23.2 (from langchain-core<0.3.0,>=0.2.24->langchain-openai)\n  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.24->langchain-openai) (2.5.3)\nRequirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.24->langchain-openai) (8.2.3)\nRequirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (4.2.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (0.27.0)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (1.3.0)\nRequirement already satisfied: tqdm>4 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (4.66.4)\nRequirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (4.9.0)\nRequirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2023.12.25)\nRequirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.32.0->langchain-openai) (3.6)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.32.0->langchain-openai) (1.2.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain-openai) (2024.7.4)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain-openai) (1.0.5)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain-openai) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.24->langchain-openai) (2.4)\nCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.24->langchain-openai)\n  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.24->langchain-openai) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.24->langchain-openai) (2.14.6)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.3.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (1.26.18)\nDownloading langchain_openai-0.1.19-py3-none-any.whl (47 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_core-0.2.24-py3-none-any.whl (377 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.3/377.3 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading openai-1.37.1-py3-none-any.whl (337 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m337.0/337.0 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langsmith-0.1.94-py3-none-any.whl (139 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.9/139.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading packaging-24.1-py3-none-any.whl (53 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: packaging, orjson, tiktoken, openai, langsmith, langchain-core, langchain-openai\n  Attempting uninstall: packaging\n    Found existing installation: packaging 21.3\n    Uninstalling packaging-21.3:\n      Successfully uninstalled packaging-21.3\n  Attempting uninstall: orjson\n    Found existing installation: orjson 3.9.10\n    Uninstalling orjson-3.9.10:\n      Successfully uninstalled orjson-3.9.10\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkeras-cv 0.9.0 requires keras-core, which is not installed.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 16.1.0 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.1 which is incompatible.\njupyterlab 4.2.3 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.2 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.9.3 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\npointpats 2.5.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nspaghetti 1.7.6 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nspopt 0.6.1 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.4.1 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed langchain-core-0.2.24 langchain-openai-0.1.19 langsmith-0.1.94 openai-1.37.1 orjson-3.10.6 packaging-24.1 tiktoken-0.7.0\n","output_type":"stream"}]},{"cell_type":"code","source":"! pip install langchain","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-07-30T12:35:50.705453Z","iopub.execute_input":"2024-07-30T12:35:50.705918Z","iopub.status.idle":"2024-07-30T12:36:07.653589Z","shell.execute_reply.started":"2024-07-30T12:35:50.705874Z","shell.execute_reply":"2024-07-30T12:36:07.652264Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true,"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Collecting langchain\n  Downloading langchain-0.2.11-py3-none-any.whl.metadata (7.1 kB)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.1)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.25)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.1)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\nRequirement already satisfied: langchain-core<0.3.0,>=0.2.23 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.2.24)\nCollecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.1.94)\nRequirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.26.4)\nRequirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.5.3)\nRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.32.3)\nRequirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.2.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.23->langchain) (1.33)\nRequirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.23->langchain) (24.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.6)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.14.6)\nRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.9.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.7.4)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.23->langchain) (2.4)\nDownloading langchain-0.2.11-py3-none-any.whl (990 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.3/990.3 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\nInstalling collected packages: langchain-text-splitters, langchain\nSuccessfully installed langchain-0.2.11 langchain-text-splitters-0.2.2\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# LLM choice and Prompts\n\nThis code sets up a system for solving math problems using a language model (LLM). Here's a brief overview:\n\n1. `get_answer(question)`: Generates a prompt for the LLM to solve a math problem step-by-step.\n\n2. `parse_answer(question, message)`: Creates a prompt for the LLM to analyze and potentially fix a given solution, then provide the final answer.\n\n3. `extract_numerical_answer(text)`: Uses regular expressions to extract the numerical answer from the LLM's response.","metadata":{}},{"cell_type":"code","source":"from langchain_openai import OpenAI\nfrom langchain.prompts import PromptTemplate\nfrom langchain_openai import ChatOpenAI\n\nllm = ChatOpenAI(model_name=\"gpt-4o-mini\",\n                 temperature=0.5,\n#                  max_tokens=\n                )","metadata":{"execution":{"iopub.status.busy":"2024-07-30T12:36:07.655879Z","iopub.execute_input":"2024-07-30T12:36:07.656280Z","iopub.status.idle":"2024-07-30T12:36:09.409836Z","shell.execute_reply.started":"2024-07-30T12:36:07.656244Z","shell.execute_reply":"2024-07-30T12:36:09.408735Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import re\n\ndef get_answer(question):\n    prompt = f\"\"\"Please solve the following high school math problem step by step. Explain your reasoning clearly and provide the final answer.\n\n{question}\n\nStep-by-step solution and final answer:\"\"\"\n\n    response = llm.invoke(prompt)\n    return response\n\ndef parse_answer(question, message):\n    prompt = f\"\"\" Please analyze the solution for a given problem, fix it if needed, and then provide the final answer.         \nYour response should end in the format: 'Hence, the final answer is [numeric string].\n    \nQ: {question}\n\nSolution: {message}\n\nAnalysis: \n    \n    \"\"\"\n    \n    response = llm.invoke(prompt)\n    return response\n\n\ndef extract_numerical_answer(text):\n    # Look for patterns like \"Final answer: X\" or \"The answer is X\" at the end of the text\n    match = re.search(r'(?:final answer|the answer is)[:\\s]*([+-]?\\d*\\.?\\d+)', text, re.IGNORECASE)\n    if match:\n        return float(match.group(1))\n    else:\n        # If no clear final answer, look for the last number in the text\n        numbers = re.findall(r'[+-]?\\d*\\.?\\d+', text)\n        return float(numbers[-1]) if numbers else 1.0","metadata":{"execution":{"iopub.status.busy":"2024-07-30T12:36:17.338328Z","iopub.execute_input":"2024-07-30T12:36:17.339192Z","iopub.status.idle":"2024-07-30T12:36:17.349211Z","shell.execute_reply.started":"2024-07-30T12:36:17.339133Z","shell.execute_reply":"2024-07-30T12:36:17.347812Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Run the loop","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\n\nGLOBAL_SOLUTIONS_FOR_SUBMISSION = []\n\nfor idx, row in tqdm(test_df.iterrows(), total=len(test_df)):\n\n    question = row['problem_text']\n    response_1 = get_answer(question)\n    response_1 = response_1.content.strip()\n    \n    response_2 = parse_answer(question, response_1)\n    response_2 = response_2.content.strip()\n    \n    numerical_answer = extract_numerical_answer(response_2)\n    \n    GLOBAL_SOLUTIONS_FOR_SUBMISSION.append({\n        'problem_id': row['problem_id'],\n        'llm_out_1': response_1,\n        'llm_out_2': response_2,\n        'answer': numerical_answer\n    })\n    \n    pd.DataFrame(GLOBAL_SOLUTIONS_FOR_SUBMISSION).to_csv('baseline_answers_with_double_check.csv', index=False)\n    ","metadata":{"execution":{"iopub.status.busy":"2024-07-30T12:36:29.248750Z","iopub.execute_input":"2024-07-30T12:36:29.249602Z","iopub.status.idle":"2024-07-30T13:00:04.347049Z","shell.execute_reply.started":"2024-07-30T12:36:29.249563Z","shell.execute_reply":"2024-07-30T13:00:04.345522Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"100%|██████████| 100/100 [23:35<00:00, 14.15s/it]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Save the outputs for further analysis and create submission file","metadata":{}},{"cell_type":"code","source":"answers_df = pd.DataFrame(GLOBAL_SOLUTIONS_FOR_SUBMISSION)\nanswers_df.to_csv('baseline_answers_with_double_check.csv', index=False)\n\ndf = answers_df[['problem_id', 'answer']]\ndf.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-07-30T13:00:04.349605Z","iopub.execute_input":"2024-07-30T13:00:04.350001Z","iopub.status.idle":"2024-07-30T13:00:04.387506Z","shell.execute_reply.started":"2024-07-30T13:00:04.349968Z","shell.execute_reply":"2024-07-30T13:00:04.385771Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-30T13:00:04.390378Z","iopub.execute_input":"2024-07-30T13:00:04.390866Z","iopub.status.idle":"2024-07-30T13:00:04.411251Z","shell.execute_reply.started":"2024-07-30T13:00:04.390818Z","shell.execute_reply":"2024-07-30T13:00:04.409854Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"   problem_id   answer\n0       11919     12.0\n1        8513  11287.6\n2        7887      4.0\n3        5272      6.0\n4        8295     13.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>problem_id</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>11919</td>\n      <td>12.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8513</td>\n      <td>11287.6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7887</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5272</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8295</td>\n      <td>13.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# What Next?\n\n**Using LLM for a double check and parsing** is a useful approach, albeit at the cost of additional API calls.\nThis method is valuable because our regex parser `extract_numerical_answer()` is simplistic and may miss correct answers.\nSo far, my best solution comes from constructing few-shot prompts using problems from `train.csv`.\nI recommend looking at these resources:\n\n* https://www.promptingguide.ai/techniques/cot\n    - Example prompt: https://github.com/FranxYao/chain-of-thought-hub/blob/main/gsm8k/lib_prompt/prompt_original.txt\n* https://www.promptingguide.ai/techniques/consistency\n    - Example prompt: https://tylerburleigh.com/blog/2023/12/04/#prompt-functions","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}